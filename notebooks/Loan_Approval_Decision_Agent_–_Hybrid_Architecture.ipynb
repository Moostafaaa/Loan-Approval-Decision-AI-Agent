{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "#  Applied Task \u2013 Loan Approval Decision Agent\n",
        "\n",
        "## Hybrid Rule-Based + LLM Explanation System\n",
        "\n",
        "\u26a0\ufe0f Important\n",
        "This is NOT a prompting exercise.\n",
        "This is a system design and rule-engine exercise.\n",
        "\n",
        "The LLM must NEVER decide the loan.\n",
        "Your Python logic must decide first.\n",
        "\n",
        "---\n",
        "\n",
        "#  LEVEL 1 \u2013 Basic Hybrid Decision Engine\n",
        "\n",
        "##  Objective\n",
        "\n",
        "Build a simple Loan Approval Decision System that:\n",
        "\n",
        "* Extracts loan amount from user input\n",
        "* Matches it against predefined rules\n",
        "* Selects one rule\n",
        "* Uses LLM only to explain the decision\n",
        "\n",
        "---\n",
        "\n",
        "# \ud83c\udfd7 Required Architecture (Level 1)\n",
        "\n",
        "User Input\n",
        "\n",
        "\u2193\n",
        "\n",
        "Extract amount\n",
        "\n",
        "\u2193\n",
        "\n",
        "Match rule condition\n",
        "\n",
        "\u2193\n",
        "\n",
        "Select first matching rule\n",
        "\n",
        "\u2193\n",
        "\n",
        "LLM explanation\n",
        "\n",
        "\u2193\n",
        "\n",
        "Structured final output\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "#  Step 1 \u2013 Create Loan Rules CSV (Level 1)\n",
        "\n",
        "Your CSV must contain:\n",
        "\n",
        "* section\n",
        "* rule_description\n",
        "* condition\n",
        "* decision\n",
        "* risk_level\n",
        "\n",
        "### Example Rules\n",
        "\n",
        "| section | rule_description         | condition       | decision      | risk_level |\n",
        "| ------- | ------------------------ | --------------- | ------------- | ---------- |\n",
        "| Loan    | Small loan auto approved | amount <= 5000  | APPROVED      | Low        |\n",
        "| Loan    | Medium loan needs review | amount <= 20000 | MANUAL_REVIEW | Medium     |\n",
        "| Loan    | High loan rejected       | amount > 20000  | REJECTED      | High       |\n",
        "\n",
        "\u26a0\ufe0f Rules must support only:\n",
        "\n",
        "* amount\n",
        "* single comparison operator\n",
        "* one numeric value\n",
        "\n",
        "No AND.\n",
        "No credit score.\n",
        "Keep it simple.\n",
        "\n",
        "---\n",
        "\n",
        "#  Step 2 \u2013 Extract Loan Amount\n",
        "\n",
        "Example input:\n",
        "\n",
        "\"I need a loan of 15000 dollars.\"\n",
        "\n",
        "Your system must:\n",
        "\n",
        "* Extract 15000\n",
        "* Assign to variable: amount\n",
        "\n",
        "Hint:\n",
        "Use regex to extract first numeric value.\n",
        "\n",
        "---\n",
        "\n",
        "#  Step 3 \u2013 Implement Safe Condition Matching\n",
        "\n",
        "You must support:\n",
        "\n",
        "* <=\n",
        "* <\n",
        "* >\n",
        "* > =\n",
        "\n",
        "Example:\n",
        "\n",
        "Condition: amount <= 5000\n",
        "\n",
        "If amount = 4000 \u2192 True\n",
        "If amount = 8000 \u2192 False\n",
        "\n",
        "\u26a0\ufe0f Do NOT use eval().\n",
        "\n",
        "Implement manual comparison logic.\n",
        "\n",
        "---\n",
        "\n",
        "#  Step 4 \u2013 Rule Selection Strategy (Level 1)\n",
        "\n",
        "Loop through rules in order.\n",
        "\n",
        "The first rule that returns True wins.\n",
        "\n",
        "Stop checking after match.\n",
        "\n",
        "---\n",
        "\n",
        "#  Step 5 \u2013 LLM Explanation Layer\n",
        "\n",
        "After selecting the rule:\n",
        "\n",
        "Send to LLM:\n",
        "\n",
        "* User input\n",
        "* Selected rule\n",
        "* Decision\n",
        "* Risk level\n",
        "\n",
        "Required Output Format:\n",
        "\n",
        "\n",
        "Decision: <APPROVED / REJECTED / MANUAL_REVIEW>\n",
        "\n",
        "Risk Level: <Low / Medium / High>\n",
        "\n",
        "Reasoning: <Short explanation>\n",
        "\n",
        "\n",
        "\u26a0\ufe0f The LLM must not change the decision.\n",
        "\n",
        "---\n",
        "\n",
        "# Step 6 \u2013 Testing (Level 1)\n",
        "\n",
        "You must test at least:\n",
        "\n",
        "3 approved cases\n",
        "3 manual review cases\n",
        "3 rejected cases\n",
        "\n",
        "Example:\n",
        "\n",
        "\"I need 2000\"\n",
        "\"I want 15000 loan\"\n",
        "\"Give me 50000\"\n",
        "\n",
        "---\n",
        "\n",
        "# Level 1 Deliverables\n",
        "\n",
        "1. Loan rules CSV\n",
        "2. Python decision engine\n",
        "3. 9 test cases\n",
        "4. Half-page explanation of:\n",
        "\n",
        "   * How rule matching works\n",
        "   * Why LLM does not decide\n",
        "\n",
        "---\n"
      ],
      "metadata": {
        "id": "RjDJWFO0eTPF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Mount Google Drive (if using Colab)\n",
        "try:\n",
        "    from google.colab import drive\n",
        "    drive.mount('/content/drive')\n",
        "    IN_COLAB = True\n",
        "except:\n",
        "    IN_COLAB = False\n",
        "    print(\"Not running in Colab\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PcbEupNQksQf",
        "outputId": "42f7c266-4b15-4e78-d800-aaf267b4234c"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install bitsandbytes accelerate"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "-fQsXLu6k_jl",
        "outputId": "482548cc-4353-46b2-886c-97798cdc06f3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting bitsandbytes\n",
            "  Downloading bitsandbytes-0.49.2-py3-none-manylinux_2_24_x86_64.whl.metadata (10 kB)\n",
            "Requirement already satisfied: accelerate in /usr/local/lib/python3.12/dist-packages (1.12.0)\n",
            "Requirement already satisfied: torch<3,>=2.3 in /usr/local/lib/python3.12/dist-packages (from bitsandbytes) (2.10.0+cu128)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.12/dist-packages (from bitsandbytes) (2.0.2)\n",
            "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.12/dist-packages (from bitsandbytes) (26.0)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.12/dist-packages (from accelerate) (5.9.5)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.12/dist-packages (from accelerate) (6.0.3)\n",
            "Requirement already satisfied: huggingface_hub>=0.21.0 in /usr/local/lib/python3.12/dist-packages (from accelerate) (1.4.1)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.12/dist-packages (from accelerate) (0.7.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from huggingface_hub>=0.21.0->accelerate) (3.24.3)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.12/dist-packages (from huggingface_hub>=0.21.0->accelerate) (2025.3.0)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.2.0 in /usr/local/lib/python3.12/dist-packages (from huggingface_hub>=0.21.0->accelerate) (1.3.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.12/dist-packages (from huggingface_hub>=0.21.0->accelerate) (0.28.1)\n",
            "Requirement already satisfied: shellingham in /usr/local/lib/python3.12/dist-packages (from huggingface_hub>=0.21.0->accelerate) (1.5.4)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.12/dist-packages (from huggingface_hub>=0.21.0->accelerate) (4.67.3)\n",
            "Requirement already satisfied: typer-slim in /usr/local/lib/python3.12/dist-packages (from huggingface_hub>=0.21.0->accelerate) (0.24.0)\n",
            "Requirement already satisfied: typing-extensions>=4.1.0 in /usr/local/lib/python3.12/dist-packages (from huggingface_hub>=0.21.0->accelerate) (4.15.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch<3,>=2.3->bitsandbytes) (75.2.0)\n",
            "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch<3,>=2.3->bitsandbytes) (1.14.0)\n",
            "Requirement already satisfied: networkx>=2.5.1 in /usr/local/lib/python3.12/dist-packages (from torch<3,>=2.3->bitsandbytes) (3.6.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch<3,>=2.3->bitsandbytes) (3.1.6)\n",
            "Requirement already satisfied: cuda-bindings==12.9.4 in /usr/local/lib/python3.12/dist-packages (from torch<3,>=2.3->bitsandbytes) (12.9.4)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.8.93 in /usr/local/lib/python3.12/dist-packages (from torch<3,>=2.3->bitsandbytes) (12.8.93)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.8.90 in /usr/local/lib/python3.12/dist-packages (from torch<3,>=2.3->bitsandbytes) (12.8.90)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.8.90 in /usr/local/lib/python3.12/dist-packages (from torch<3,>=2.3->bitsandbytes) (12.8.90)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch<3,>=2.3->bitsandbytes) (9.10.2.21)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.8.4.1 in /usr/local/lib/python3.12/dist-packages (from torch<3,>=2.3->bitsandbytes) (12.8.4.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.3.3.83 in /usr/local/lib/python3.12/dist-packages (from torch<3,>=2.3->bitsandbytes) (11.3.3.83)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.9.90 in /usr/local/lib/python3.12/dist-packages (from torch<3,>=2.3->bitsandbytes) (10.3.9.90)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.7.3.90 in /usr/local/lib/python3.12/dist-packages (from torch<3,>=2.3->bitsandbytes) (11.7.3.90)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.5.8.93 in /usr/local/lib/python3.12/dist-packages (from torch<3,>=2.3->bitsandbytes) (12.5.8.93)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch<3,>=2.3->bitsandbytes) (0.7.1)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.27.5 in /usr/local/lib/python3.12/dist-packages (from torch<3,>=2.3->bitsandbytes) (2.27.5)\n",
            "Requirement already satisfied: nvidia-nvshmem-cu12==3.4.5 in /usr/local/lib/python3.12/dist-packages (from torch<3,>=2.3->bitsandbytes) (3.4.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.8.90 in /usr/local/lib/python3.12/dist-packages (from torch<3,>=2.3->bitsandbytes) (12.8.90)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.8.93 in /usr/local/lib/python3.12/dist-packages (from torch<3,>=2.3->bitsandbytes) (12.8.93)\n",
            "Requirement already satisfied: nvidia-cufile-cu12==1.13.1.3 in /usr/local/lib/python3.12/dist-packages (from torch<3,>=2.3->bitsandbytes) (1.13.1.3)\n",
            "Requirement already satisfied: triton==3.6.0 in /usr/local/lib/python3.12/dist-packages (from torch<3,>=2.3->bitsandbytes) (3.6.0)\n",
            "Requirement already satisfied: cuda-pathfinder~=1.1 in /usr/local/lib/python3.12/dist-packages (from cuda-bindings==12.9.4->torch<3,>=2.3->bitsandbytes) (1.3.5)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.23.0->huggingface_hub>=0.21.0->accelerate) (4.12.1)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.23.0->huggingface_hub>=0.21.0->accelerate) (2026.1.4)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.23.0->huggingface_hub>=0.21.0->accelerate) (1.0.9)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.23.0->huggingface_hub>=0.21.0->accelerate) (3.11)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.12/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->huggingface_hub>=0.21.0->accelerate) (0.16.0)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch<3,>=2.3->bitsandbytes) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch<3,>=2.3->bitsandbytes) (3.0.3)\n",
            "Requirement already satisfied: typer>=0.24.0 in /usr/local/lib/python3.12/dist-packages (from typer-slim->huggingface_hub>=0.21.0->accelerate) (0.24.1)\n",
            "Requirement already satisfied: click>=8.2.1 in /usr/local/lib/python3.12/dist-packages (from typer>=0.24.0->typer-slim->huggingface_hub>=0.21.0->accelerate) (8.3.1)\n",
            "Requirement already satisfied: rich>=12.3.0 in /usr/local/lib/python3.12/dist-packages (from typer>=0.24.0->typer-slim->huggingface_hub>=0.21.0->accelerate) (13.9.4)\n",
            "Requirement already satisfied: annotated-doc>=0.0.2 in /usr/local/lib/python3.12/dist-packages (from typer>=0.24.0->typer-slim->huggingface_hub>=0.21.0->accelerate) (0.0.4)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.12/dist-packages (from rich>=12.3.0->typer>=0.24.0->typer-slim->huggingface_hub>=0.21.0->accelerate) (4.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.12/dist-packages (from rich>=12.3.0->typer>=0.24.0->typer-slim->huggingface_hub>=0.21.0->accelerate) (2.19.2)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.12/dist-packages (from markdown-it-py>=2.2.0->rich>=12.3.0->typer>=0.24.0->typer-slim->huggingface_hub>=0.21.0->accelerate) (0.1.2)\n",
            "Downloading bitsandbytes-0.49.2-py3-none-manylinux_2_24_x86_64.whl (60.7 MB)\n",
            "\u001b[2K   \u001b[90m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m \u001b[32m60.7/60.7 MB\u001b[0m \u001b[31m16.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: bitsandbytes\n",
            "Successfully installed bitsandbytes-0.49.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# -------------------------\n",
        "# 0) Setup & Imports\n",
        "# -------------------------\n",
        "import json\n",
        "import re\n",
        "import torch\n",
        "import pandas as pd\n",
        "from typing import Dict, Any, Tuple, Optional, List\n",
        "\n",
        "from transformers import AutoTokenizer, AutoModelForCausalLM, BitsAndBytesConfig, pipeline\n",
        "\n",
        "\n",
        "# -------------------------\n",
        "# 1) Load Model (same approach)\n",
        "# -------------------------\n",
        "# Change these paths to match your environment\n",
        "model_path = \"/content/drive/MyDrive/Phi_3_5_mini_instruct\"\n",
        "\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "print(\"Device:\", device)\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(\n",
        "    model_path,\n",
        "    local_files_only=True\n",
        ")\n",
        "\n",
        "bnb_config = BitsAndBytesConfig(\n",
        "    load_in_4bit=True,\n",
        "    bnb_4bit_compute_dtype=torch.float16,\n",
        "    bnb_4bit_quant_type=\"nf4\"\n",
        ")\n",
        "\n",
        "model = AutoModelForCausalLM.from_pretrained(\n",
        "    model_path,\n",
        "    device_map=\"auto\",\n",
        "    quantization_config=bnb_config,\n",
        "    torch_dtype=torch.float16,\n",
        "    local_files_only=True\n",
        ")\n",
        "\n",
        "print(\"\u2705 Model & tokenizer loaded\")"
      ],
      "metadata": {
        "id": "ZxBMLsukk6vY",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 84,
          "referenced_widgets": [
            "566aac5599444e3e8331ca275f81eb7b",
            "a606cb536dd542cc980ddfda182bdf0f",
            "2480762e241044d3854a35b5a8560413",
            "54840132f79b4858a7abc5cf6e66ee50",
            "a824eee42423403b86e5875b11c257ab",
            "785793d52cde4336b4672b78e432b210",
            "92dc7eeead7e42d681b937858303ee2d",
            "432c1708265341a2a678cad8dfb22ca7",
            "1a92969621fd4afaa3b758dd958996e3",
            "749b678b67984e78854c7f22bf1b2a74",
            "1a02e60f9c1147c8bda2ea1bbd33b087"
          ]
        },
        "outputId": "8aa65a68-bf40-4458-c38d-bcee32e6cb5d"
      },
      "execution_count": 93,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Device: cuda\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Loading weights:   0%|          | 0/195 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "566aac5599444e3e8331ca275f81eb7b"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u2705 Model & tokenizer loaded\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df=pd.read_csv(\"loan_rules.csv\")\n",
        "print(df.head())\n",
        "print(\"Columns:\", df.columns)"
      ],
      "metadata": {
        "id": "EV3GG6EjoX1l",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5a051d93-8aea-4324-cab4-73758a4b7eac"
      },
      "execution_count": 78,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "          section            rule_description        condition  decision  \\\n",
            "0     Micro_Loans  Nano loan instant approval   amount <= 1000  APPROVED   \n",
            "1     Micro_Loans          Small starter loan   amount <= 2500  APPROVED   \n",
            "2  Consumer_Loans        Standard retail loan   amount <= 5000  APPROVED   \n",
            "3  Consumer_Loans        Elevated retail loan   amount <= 7500  APPROVED   \n",
            "4  Consumer_Loans         Premium retail loan  amount <= 10000  APPROVED   \n",
            "\n",
            "  risk_level  \n",
            "0        Low  \n",
            "1        Low  \n",
            "2        Low  \n",
            "3        Low  \n",
            "4     Medium  \n",
            "Columns: Index(['section', 'rule_description', 'condition', 'decision', 'risk_level'], dtype='object')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\n",
        "# STEP 1: PARSE RULES FROM YOUR DATAFRAME\n",
        "# \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\n",
        "def parse_condition(condition_str: str) -> tuple:\n",
        "    \"\"\"\n",
        "    Parse \"amount <= 1000\" \u2192 (\"amount\", \"<=\", 1000.0)\n",
        "    Supports: <=, >=, <, >, =, !=\n",
        "    \"\"\"\n",
        "    pattern = r\"(\\w+)\\s*(<=|>=|!=|<|>|=)\\s*([\\d.]+)\"\n",
        "    match = re.match(pattern, condition_str.strip())\n",
        "    if not match:\n",
        "        raise ValueError(f\"Cannot parse condition: '{condition_str}'\")\n",
        "    return (match.group(1), match.group(2), float(match.group(3)))\n",
        "\n",
        "\n",
        "def load_rules_from_df(rules_df: pd.DataFrame) -> list[dict]:\n",
        "    \"\"\"\n",
        "    Convert each DataFrame row into a rule dict.\n",
        "    Row order = rule priority (first match wins).\n",
        "\n",
        "    Required columns: section, rule_description, condition, decision, risk_level\n",
        "    \"\"\"\n",
        "    rules = []\n",
        "    for idx, row in rules_df.iterrows():\n",
        "        rules.append({\n",
        "            \"id\":            idx,\n",
        "            \"section\":       row[\"section\"],\n",
        "            \"label\":         row[\"rule_description\"],\n",
        "            \"condition_str\": row[\"condition\"],\n",
        "            \"condition\":     parse_condition(row[\"condition\"]),\n",
        "            \"decision\":      row[\"decision\"],\n",
        "            \"risk_level\":    row[\"risk_level\"],\n",
        "        })\n",
        "    return rules\n",
        "\n"
      ],
      "metadata": {
        "id": "MoUN7Z32T1Lt"
      },
      "execution_count": 79,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "fkkTyVHcVkb4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\n",
        "# STEP 2: EXTRACT LOAN AMOUNT FROM USER INPUT\n",
        "# \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\n",
        "def extract_amount(user_input: str) -> float | None:\n",
        "    \"\"\"\n",
        "    Extract first numeric value from free-text input.\n",
        "    Handles: $15,000  |  15000  |  15.5k  |  \"$500\"\n",
        "    \"\"\"\n",
        "    cleaned = user_input.replace(\",\", \"\")\n",
        "\n",
        "    # Handle shorthand: \"15k\" \u2192 15000\n",
        "    k_match = re.search(r\"\\$?(\\d+(?:\\.\\d+)?)\\s*k\\b\", cleaned, re.IGNORECASE)\n",
        "    if k_match:\n",
        "        return float(k_match.group(1)) * 1000\n",
        "\n",
        "    match = re.search(r\"\\$?(\\d+(?:\\.\\d+)?)\", cleaned)\n",
        "    return float(match.group(1)) if match else None\n",
        "\n"
      ],
      "metadata": {
        "id": "XnyLxlMYT1Q8"
      },
      "execution_count": 80,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluate_condition(amount: float, condition: tuple) -> bool:\n",
        "    \"\"\"\n",
        "    Manually evaluate (field, operator, threshold).\n",
        "    \u26a0\ufe0f Never uses eval().\n",
        "    \"\"\"\n",
        "    _, operator, threshold = condition\n",
        "    operator = operator.strip()\n",
        "\n",
        "    if operator == \"<=\":\n",
        "        return amount <= threshold\n",
        "    elif operator == \"<\":\n",
        "        return amount < threshold\n",
        "    elif operator == \">=\":\n",
        "        return amount >= threshold\n",
        "    elif operator == \">\":\n",
        "        return amount > threshold\n",
        "    elif operator == \"=\":\n",
        "        return amount == threshold\n",
        "    elif operator == \"!=\":\n",
        "        return amount != threshold\n",
        "    else:\n",
        "        raise ValueError(f\"Unsupported operator: {operator}\")"
      ],
      "metadata": {
        "id": "UQtnm9vyT1TQ"
      },
      "execution_count": 96,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\n",
        "# STEP 4: RULE SELECTION (first-match wins)\n",
        "# \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\n",
        "def select_rule(amount: float, rules: list[dict]) -> dict | None:\n",
        "    \"\"\"\n",
        "    Loop through rules in DataFrame order.\n",
        "    Return FIRST rule whose condition evaluates to True.\n",
        "    \u26a0\ufe0f Python decides \u2014 NOT the LLM.\n",
        "    \"\"\"\n",
        "    for rule in rules:\n",
        "        if evaluate_condition(amount, rule[\"condition\"]):\n",
        "            return rule\n",
        "    return None\n"
      ],
      "metadata": {
        "id": "bnfxFNbEVlyD"
      },
      "execution_count": 82,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\n",
        "# STEP 5: LLM EXPLANATION LAYER\n",
        "# \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\n",
        "def build_prompt(user_input: str, amount: float, rule: dict) -> str:\n",
        "    return (\n",
        "        \"You are a professional loan officer assistant. \"\n",
        "        \"A loan decision has already been made by our rule engine. \"\n",
        "        \"Your ONLY job is to write a clear, professional one sentence explanation \"\n",
        "        \"for the applicant. Do NOT change, question, or override the decision.\\n\\n\"\n",
        "        f\"Applicant Request : \\\"{user_input}\\\"\\n\"\n",
        "        f\"Loan Amount       : ${amount:,.0f}\\n\"\n",
        "        f\"Loan Category     : {rule['section']}\\n\"\n",
        "        f\"Applied Rule      : {rule['label']}\\n\"\n",
        "        f\"Condition Met     : {rule['condition_str']}\\n\"\n",
        "        f\"Decision          : {rule['decision']}\\n\"\n",
        "        f\"Risk Level        : {rule['risk_level']}\\n\\n\"\n",
        "        \"Explanation:\"\n",
        "    )\n",
        "\n",
        "\n",
        "def get_llm_explanation(pipe, user_input: str, amount: float, rule: dict) -> str:\n",
        "    \"\"\"Call Phi-3.5-mini-instruct to generate an explanation (never the decision).\"\"\"\n",
        "    messages = [{\"role\": \"user\", \"content\": build_prompt(user_input, amount, rule)}]\n",
        "    output = pipe(messages, max_new_tokens=150, do_sample=False)\n",
        "\n",
        "    response = output[0][\"generated_text\"]\n",
        "    if isinstance(response, list):\n",
        "        for msg in reversed(response):\n",
        "            if isinstance(msg, dict) and msg.get(\"role\") == \"assistant\":\n",
        "                return msg[\"content\"].strip()\n",
        "    return str(response).strip()"
      ],
      "metadata": {
        "id": "Y0wgf78JVsxP"
      },
      "execution_count": 99,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "fWxaun11V11c"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\n",
        "# STEP 6: MAIN DECISION PIPELINE\n",
        "# \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\n",
        "def process_loan_application(pipe, user_input: str, rules: list[dict]) -> dict:\n",
        "    \"\"\"\n",
        "    Single application pipeline:\n",
        "      Extract amount \u2192 Select rule (Python) \u2192 LLM explains \u2192 Structured output\n",
        "    \"\"\"\n",
        "    amount = extract_amount(user_input)\n",
        "\n",
        "    if amount is None:\n",
        "        return {\n",
        "            \"user_input\":    user_input,\n",
        "            \"amount\":        None,\n",
        "            \"section\":       \"N/A\",\n",
        "            \"matched_rule\":  \"N/A\",\n",
        "            \"condition_met\": \"N/A\",\n",
        "            \"decision\":      \"ERROR\",\n",
        "            \"risk_level\":    \"N/A\",\n",
        "            \"reasoning\":     \"Could not extract a loan amount from the input.\",\n",
        "        }\n",
        "\n",
        "    rule = select_rule(amount, rules)\n",
        "\n",
        "    if rule is None:\n",
        "        return {\n",
        "            \"user_input\":    user_input,\n",
        "            \"amount\":        amount,\n",
        "            \"section\":       \"N/A\",\n",
        "            \"matched_rule\":  \"No rule matched\",\n",
        "            \"condition_met\": \"N/A\",\n",
        "            \"decision\":      \"REJECTED\",\n",
        "            \"risk_level\":    \"High\",\n",
        "            \"reasoning\":     \"No applicable rule found for this loan amount.\",\n",
        "        }\n",
        "\n",
        "    return {\n",
        "        \"user_input\":    user_input,\n",
        "        \"amount\":        amount,\n",
        "        \"section\":       rule[\"section\"],\n",
        "        \"matched_rule\":  rule[\"label\"],\n",
        "        \"condition_met\": rule[\"condition_str\"],\n",
        "        \"decision\":      rule[\"decision\"],      # \u2190 Set by Python rule engine\n",
        "        \"risk_level\":    rule[\"risk_level\"],    # \u2190 Set by Python rule engine\n",
        "        \"reasoning\":     get_llm_explanation(pipe, user_input, amount, rule),  # \u2190 LLM only\n",
        "    }\n",
        "\n",
        "\n",
        "def print_result(result: dict):\n",
        "    icons = {\"APPROVED\": \"\u2705\", \"MANUAL_REVIEW\": \"\ud83d\udd0d\", \"REJECTED\": \"\u274c\", \"ERROR\": \"\u26a0\ufe0f\"}\n",
        "    icon  = icons.get(result[\"decision\"], \"\")\n",
        "    amt   = f\"${result['amount']:,.0f}\" if result[\"amount\"] is not None else \"N/A\"\n",
        "    print(\"=\" * 65)\n",
        "    print(f\"  Input      : {result['user_input']}\")\n",
        "    print(f\"  Amount     : {amt}\")\n",
        "    print(f\"  Section    : {result['section']}\")\n",
        "    print(f\"  Rule       : {result['matched_rule']}\")\n",
        "    print(f\"  Condition  : {result['condition_met']}\")\n",
        "    print(f\"  Decision   : {icon} {result['decision']}\")\n",
        "    print(f\"  Risk Level : {result['risk_level']}\")\n",
        "    print(f\"  Reasoning  :\")\n",
        "    print(f\"    {result['reasoning']}\")\n",
        "    print(\"=\" * 65 + \"\\n\")\n",
        "\n"
      ],
      "metadata": {
        "id": "GKgYToZ0T1WD"
      },
      "execution_count": 84,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\n",
        "# STEP 7: USER QUERY FUNCTION\n",
        "# \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\n",
        "\n",
        "# Load rules and model once at module level\n",
        "_rules = load_rules_from_df(df)\n",
        "\n",
        "# Initialize the text generation pipeline\n",
        "text_generation_pipeline = pipeline(\n",
        "    \"text-generation\",\n",
        "    model=model,\n",
        "    tokenizer=tokenizer,\n",
        "    max_length=150 # Set max_length here to match max_new_tokens in get_llm_explanation\n",
        ")\n",
        "\n",
        "def user_query(query: str):\n",
        "    \"\"\"\n",
        "    Process a single loan request query.\n",
        "    \"\"\"\n",
        "    result = process_loan_application(text_generation_pipeline, query, _rules)\n",
        "    print_result(result)"
      ],
      "metadata": {
        "id": "gy-V-TTCT1ZL",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dc4b5d72-7225-4c51-8fde-8fa6fd4f0ecd"
      },
      "execution_count": 98,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Passing `generation_config` together with generation-related arguments=({'max_length'}) is deprecated and will be removed in future versions. Please pass either a `generation_config` object OR all generation parameters explicitly, but not both.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "user_query(\"i need 85,000 dollars\") #1"
      ],
      "metadata": {
        "id": "4r9yoo6ReTGb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0be44692-6d48-4d00-ab67-dd7eeb3fc279"
      },
      "execution_count": 102,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Both `max_new_tokens` (=150) and `max_length`(=150) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "=================================================================\n",
            "  Input      : i need 85,000 dollars\n",
            "  Amount     : $85,000\n",
            "  Section    : Large_Loans\n",
            "  Rule       : Major business loan\n",
            "  Condition  : amount <= 100000\n",
            "  Decision   : \ud83d\udd0d MANUAL_REVIEW\n",
            "  Risk Level : High\n",
            "  Reasoning  :\n",
            "    The loan request for $85,000 in a Major Business Loan category has been flagged for MANUAL_REVIEW due to a High risk level, despite meeting the condition of amount <= $100,000.\n",
            "=================================================================\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "fI97hkmJ1s9Y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "user_query(\"I need $800 to fix my phone.\") #2"
      ],
      "metadata": {
        "id": "f7F1ASG4epNb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "39cc5900-e06e-44cb-8dce-43ad07b0f5dc"
      },
      "execution_count": 103,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Both `max_new_tokens` (=150) and `max_length`(=150) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "=================================================================\n",
            "  Input      : I need $800 to fix my phone.\n",
            "  Amount     : $800\n",
            "  Section    : Micro_Loans\n",
            "  Rule       : Nano loan instant approval\n",
            "  Condition  : amount <= 1000\n",
            "  Decision   : \u2705 APPROVED\n",
            "  Risk Level : Low\n",
            "  Reasoning  :\n",
            "    Your request for a $800 micro-loan for phone repairs has been approved under our Nano loan instant approval rule, as the amount requested is within our limit and deemed to carry a low risk level.\n",
            "=================================================================\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "user_query(\"I'd like to borrow $7500 for home appliances.\") #3"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EHU-7gIUahOg",
        "outputId": "090cdbc3-d1e0-41a4-8322-8be02952c19e"
      },
      "execution_count": 104,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Both `max_new_tokens` (=150) and `max_length`(=150) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "=================================================================\n",
            "  Input      : I'd like to borrow $7500 for home appliances.\n",
            "  Amount     : $7,500\n",
            "  Section    : Consumer_Loans\n",
            "  Rule       : Elevated retail loan\n",
            "  Condition  : amount <= 7500\n",
            "  Decision   : \u2705 APPROVED\n",
            "  Risk Level : Low\n",
            "  Reasoning  :\n",
            "    Your application for a $7,500 elevated retail loan for home appliances has been approved with a low risk assessment.\n",
            "=================================================================\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "user_query(\"Please approve a loan of $45,000 for renovation.\") #4"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XV7xyUHta0JR",
        "outputId": "3cbdf291-8098-432c-b3bb-464dbe81cc02"
      },
      "execution_count": 105,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Both `max_new_tokens` (=150) and `max_length`(=150) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "=================================================================\n",
            "  Input      : Please approve a loan of $45,000 for renovation.\n",
            "  Amount     : $45,000\n",
            "  Section    : Large_Loans\n",
            "  Rule       : Entry business loan\n",
            "  Condition  : amount <= 50000\n",
            "  Decision   : \ud83d\udd0d MANUAL_REVIEW\n",
            "  Risk Level : High\n",
            "  Reasoning  :\n",
            "    The loan request for $45,000 for renovation has been flagged for a MANUAL_REVIEW due to a high risk level, despite meeting the condition of being less than or equal to $50,000, as per the Entry Business Loan rule.\n",
            "=================================================================\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "user_query(\"Apply for 500k loan for my company.\") #5"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MTrh5Mt4a7nw",
        "outputId": "8987849c-3829-4fd4-9f79-1a14b5097562"
      },
      "execution_count": 106,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Both `max_new_tokens` (=150) and `max_length`(=150) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "=================================================================\n",
            "  Input      : Apply for 500k loan for my company.\n",
            "  Amount     : $500,000\n",
            "  Section    : Hard_Limits\n",
            "  Rule       : Excessive individual risk\n",
            "  Condition  : amount > 100000\n",
            "  Decision   : \u274c REJECTED\n",
            "  Risk Level : High\n",
            "  Reasoning  :\n",
            "    The loan application for $500,000 for your company has been rejected due to an identified excessive individual risk, as the amount exceeds the 100,000 threshold and is categorized under 'Hard_Limits,' resulting in a high-risk assessment.\n",
            "=================================================================\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### How Rule Matching Works\n",
        "The rule engine reads every rule directly from your DataFrame, preserving the exact row order. When a user submits a query, the system first extracts the numeric loan amount from the free-text input using regex. It then walks through the rules one by one, from row 0 downward, and evaluates each condition \u2014 such as amount <= 1000 or amount <= 25000 \u2014 using a manual comparison function that explicitly checks the operator without ever calling Python's eval(). The moment a condition returns True, that rule is selected and the loop stops immediately. This \"first-match wins\" strategy means the most specific, lowest-threshold rules at the top of the DataFrame always take priority over broader rules further down. If no rule matches at all, the system defaults to REJECTED. The result is a deterministic, fully traceable decision where every outcome can be explained by pointing to a single row in your DataFrame.\n",
        "### Why the LLM Does Not Decide\n",
        "The LLM's role is strictly limited to writing the explanation after the decision has already been made by the rule engine. By the time the model receives any input, the decision, risk level, matched rule, and condition are all finalized and passed in as fixed context. The prompt explicitly instructs the model not to change, question, or override the decision \u2014 it is only asked to translate the structured output into a professional, human-readable sentence or two. This separation exists for two critical reasons. First, LLMs are probabilistic \u2014 given the same input twice, they may produce different outputs, which makes them fundamentally unsuitable for consistent, auditable financial decisions. Second, regulatory and compliance frameworks in lending require that every decision be fully explainable and traceable back to a documented rule, something a neural network cannot provide on its own. Keeping the LLM in an explanation-only role gives you the best of both worlds: reliable, rule-based decisions that can be audited, and natural language output that communicates those decisions clearly to the applicant."
      ],
      "metadata": {
        "id": "uk-mO9PxbR0S"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "---\n",
        "\n",
        "# LEVEL 2 \u2013 Extended Hybrid Decision Engine\n",
        "\n",
        "\u26a0\ufe0f Complete Level 1 first.\n",
        "\n",
        "---\n",
        "\n",
        "## Objective\n",
        "\n",
        "Upgrade your system to support:\n",
        "\n",
        "* Multiple variables\n",
        "* AND conditions\n",
        "* Rule priority strategy\n",
        "* Fallback handling\n",
        "\n",
        "---\n",
        "\n",
        "#  Required Architecture (Level 2)\n",
        "\n",
        "User Input\n",
        "\n",
        "\u2193\n",
        "\n",
        "Extract multiple variables\n",
        "\n",
        "\u2193\n",
        "\n",
        "Parse AND conditions\n",
        "\n",
        "\u2193\n",
        "\n",
        "Evaluate rule logic\n",
        "\n",
        "\u2193\n",
        "\n",
        "Apply priority strategy\n",
        "\n",
        "\u2193\n",
        "\n",
        "Select final rule\n",
        "\n",
        "\u2193\n",
        "\n",
        "LLM explanation\n",
        "\n",
        "\u2193\n",
        "\n",
        "Structured output\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "#  Step 1 \u2013 Update Loan Rules CSV\n",
        "\n",
        "Now support:\n",
        "\n",
        "* amount\n",
        "* credit_score\n",
        "* AND conditions\n",
        "* chained numeric condition\n",
        "\n",
        "Example:\n",
        "\n",
        "| section | rule_description                   | condition                             | decision      | risk_level |\n",
        "| ------- | ---------------------------------- | ------------------------------------- | ------------- | ---------- |\n",
        "| Loan    | Small loan auto approved           | amount <= 5000                        | APPROVED      | Low        |\n",
        "| Loan    | Medium loan review                 | 5000 < amount <= 20000                | MANUAL_REVIEW | Medium     |\n",
        "| Loan    | High loan with low credit rejected | amount > 20000 AND credit_score < 700 | REJECTED      | High       |\n",
        "| Loan    | Very low credit score rejection    | credit_score < 600                    | REJECTED      | High       |\n",
        "\n",
        "---\n",
        "\n",
        "#  Step 2 \u2013 Extract Multiple Variables\n",
        "\n",
        "Example input:\n",
        "\n",
        "\"I want a loan of 25000. My credit score is 680.\"\n",
        "\n",
        "Expected:\n",
        "\n",
        "amount = 25000\n",
        "credit_score = 680\n",
        "\n",
        "Hint:\n",
        "Use keyword detection:\n",
        "\n",
        "* If sentence contains \"loan\" \u2192 assign number to amount\n",
        "* If contains \"credit\" \u2192 assign number to credit_score\n",
        "\n",
        "If missing variable \u2192 handle safely.\n",
        "\n",
        "---\n",
        "\n",
        "#  Step 3 \u2013 Implement AND Logic\n",
        "\n",
        "Example condition:\n",
        "\n",
        "amount > 20000 AND credit_score < 700\n",
        "\n",
        "You must:\n",
        "\n",
        "1. Split condition by \"AND\"\n",
        "2. Evaluate each part separately\n",
        "3. Return True only if ALL parts are True\n",
        "\n",
        "No eval().\n",
        "\n",
        "---\n",
        "\n",
        "#  Step 4 \u2013 Implement Rule Priority Strategy\n",
        "\n",
        "Multiple rules may match.\n",
        "\n",
        "You must define a strategy.\n",
        "\n",
        "Recommended strategy:\n",
        "\n",
        "1\ufe0f\u20e3 Higher risk_level wins\n",
        "High > Medium > Low\n",
        "\n",
        "2\ufe0f\u20e3 If same risk level \u2192 first match wins\n",
        "\n",
        "Document your strategy in README.\n",
        "\n",
        "---\n",
        "\n",
        "#  Step 5 \u2013 Add Fallback Handling\n",
        "\n",
        "If:\n",
        "\n",
        "* No rule matches\n",
        "* Missing required variable\n",
        "* Input unclear\n",
        "\n",
        "Return:\n",
        "\n",
        "Decision: NEED_MORE_INFORMATION\n",
        "\n",
        "Risk Level: Unknown\n",
        "\n",
        "Reasoning: Missing required information.\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "# Step 6 \u2013 Testing (Level 2)\n",
        "\n",
        "You must test:\n",
        "\n",
        "5 low-risk\n",
        "\n",
        "5 medium-risk\n",
        "\n",
        "5 high-risk\n",
        "\n",
        "3 missing-variable cases\n",
        "\n",
        "\n",
        "Example edge case:\n",
        "\n",
        "\"I need a big loan but my credit is bad.\"\n",
        "\n",
        "Describe how your system behaves.\n",
        "\n",
        "---\n",
        "\n",
        "# Level 2 Deliverables\n",
        "\n",
        "1. Updated Loan rules CSV\n",
        "2. Updated Python decision engine\n",
        "3. 15+ test cases\n",
        "4. 1-page explanation covering:\n",
        "\n",
        "   * AND logic implementation\n",
        "   * Rule priority strategy\n",
        "   * Fallback behavior\n",
        "   * System limitations\n",
        "\n",
        "---\n",
        "\n",
        "# Learning Outcome\n",
        "\n",
        "After Level 2, you should understand:\n",
        "\n",
        "* Difference between rule engine and LLM\n",
        "* Hybrid architecture design\n",
        "* Safe condition parsing\n",
        "* Deterministic decision systems\n",
        "* Basic conflict resolution\n"
      ],
      "metadata": {
        "id": "xyF8zM3xzVEf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.DataFrame({\n",
        "    \"section\": [\"Loan\"] * 7,\n",
        "    \"rule_description\": [\n",
        "        \"Small loan auto approved\",\n",
        "        \"Medium loan with good credit approved\",\n",
        "        \"Medium loan review\",\n",
        "        \"High loan with good credit manual review\",\n",
        "        \"High loan with low credit rejected\",\n",
        "        \"Very low credit score rejection\",\n",
        "        \"Very large loan rejection\",\n",
        "    ],\n",
        "    \"condition\": [\n",
        "        \"amount <= 5000\",\n",
        "        \"5000 < amount <= 20000 AND credit_score >= 700\",\n",
        "        \"5000 < amount <= 20000\",\n",
        "        \"amount > 20000 AND credit_score >= 700\",\n",
        "        \"amount > 20000 AND credit_score < 700\",\n",
        "        \"credit_score < 600\",\n",
        "        \"amount > 100000\",\n",
        "    ],\n",
        "    \"decision\": [\n",
        "        \"APPROVED\",\n",
        "        \"APPROVED\",\n",
        "        \"MANUAL_REVIEW\",\n",
        "        \"MANUAL_REVIEW\",\n",
        "        \"REJECTED\",\n",
        "        \"REJECTED\",\n",
        "        \"REJECTED\",\n",
        "    ],\n",
        "    \"risk_level\": [\n",
        "        \"Low\",\n",
        "        \"Low\",\n",
        "        \"Medium\",\n",
        "        \"Medium\",\n",
        "        \"High\",\n",
        "        \"High\",\n",
        "        \"High\",\n",
        "    ],\n",
        "})\n",
        "df.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "UqUVIicGeom4",
        "outputId": "3a232f36-d9c2-45fc-d1a9-0048285be88c"
      },
      "execution_count": 107,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "  section                          rule_description  \\\n",
              "0    Loan                  Small loan auto approved   \n",
              "1    Loan     Medium loan with good credit approved   \n",
              "2    Loan                        Medium loan review   \n",
              "3    Loan  High loan with good credit manual review   \n",
              "4    Loan        High loan with low credit rejected   \n",
              "\n",
              "                                        condition       decision risk_level  \n",
              "0                                  amount <= 5000       APPROVED        Low  \n",
              "1  5000 < amount <= 20000 AND credit_score >= 700       APPROVED        Low  \n",
              "2                          5000 < amount <= 20000  MANUAL_REVIEW     Medium  \n",
              "3          amount > 20000 AND credit_score >= 700  MANUAL_REVIEW     Medium  \n",
              "4           amount > 20000 AND credit_score < 700       REJECTED       High  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-0fe36e8b-526b-49d2-935d-96e4f2a5d2c3\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>section</th>\n",
              "      <th>rule_description</th>\n",
              "      <th>condition</th>\n",
              "      <th>decision</th>\n",
              "      <th>risk_level</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Loan</td>\n",
              "      <td>Small loan auto approved</td>\n",
              "      <td>amount &lt;= 5000</td>\n",
              "      <td>APPROVED</td>\n",
              "      <td>Low</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Loan</td>\n",
              "      <td>Medium loan with good credit approved</td>\n",
              "      <td>5000 &lt; amount &lt;= 20000 AND credit_score &gt;= 700</td>\n",
              "      <td>APPROVED</td>\n",
              "      <td>Low</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Loan</td>\n",
              "      <td>Medium loan review</td>\n",
              "      <td>5000 &lt; amount &lt;= 20000</td>\n",
              "      <td>MANUAL_REVIEW</td>\n",
              "      <td>Medium</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Loan</td>\n",
              "      <td>High loan with good credit manual review</td>\n",
              "      <td>amount &gt; 20000 AND credit_score &gt;= 700</td>\n",
              "      <td>MANUAL_REVIEW</td>\n",
              "      <td>Medium</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Loan</td>\n",
              "      <td>High loan with low credit rejected</td>\n",
              "      <td>amount &gt; 20000 AND credit_score &lt; 700</td>\n",
              "      <td>REJECTED</td>\n",
              "      <td>High</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-0fe36e8b-526b-49d2-935d-96e4f2a5d2c3')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-0fe36e8b-526b-49d2-935d-96e4f2a5d2c3 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-0fe36e8b-526b-49d2-935d-96e4f2a5d2c3');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df",
              "summary": "{\n  \"name\": \"df\",\n  \"rows\": 7,\n  \"fields\": [\n    {\n      \"column\": \"section\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          \"Loan\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"rule_description\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 7,\n        \"samples\": [\n          \"Small loan auto approved\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"condition\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 7,\n        \"samples\": [\n          \"amount <= 5000\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"decision\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 3,\n        \"samples\": [\n          \"APPROVED\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"risk_level\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 3,\n        \"samples\": [\n          \"Low\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 107
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\n",
        "# STEP 1: PARSE RULES FROM YOUR DATAFRAME\n",
        "# \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\n",
        "CHAINED_PATTERN = re.compile(\n",
        "    r\"([\\d.]+)\\s*(<=|<|>=|>)\\s*(\\w+)\\s*(<=|<|>=|>)\\s*([\\d.]+)\"\n",
        ")\n",
        "SIMPLE_PATTERN = re.compile(\n",
        "    r\"(\\w+)\\s*(<=|>=|!=|<|>|=)\\s*([\\d.]+)\"\n",
        ")\n",
        "\n",
        "\n",
        "def parse_single_condition(cond_str: str) -> dict:\n",
        "    \"\"\"\n",
        "    Parse one condition string (no AND) into a structured dict.\n",
        "\n",
        "    Handles two forms:\n",
        "      Simple  : \"amount <= 5000\"          \u2192 {type: simple,  field, op, threshold}\n",
        "      Chained : \"5000 < amount <= 20000\"  \u2192 {type: chained, field, low, low_op, high, high_op}\n",
        "    \"\"\"\n",
        "    cond_str = cond_str.strip()\n",
        "\n",
        "    # Try chained first: e.g. \"5000 < amount <= 20000\"\n",
        "    m = CHAINED_PATTERN.match(cond_str)\n",
        "    if m:\n",
        "        return {\n",
        "            \"type\":    \"chained\",\n",
        "            \"field\":   m.group(3),\n",
        "            \"low\":     float(m.group(1)),\n",
        "            \"low_op\":  m.group(2),\n",
        "            \"high\":    float(m.group(5)),\n",
        "            \"high_op\": m.group(4),\n",
        "        }\n",
        "\n",
        "    # Try simple: e.g. \"amount <= 5000\"\n",
        "    m = SIMPLE_PATTERN.match(cond_str)\n",
        "    if m:\n",
        "        return {\n",
        "            \"type\":      \"simple\",\n",
        "            \"field\":     m.group(1),\n",
        "            \"op\":        m.group(2),\n",
        "            \"threshold\": float(m.group(3)),\n",
        "        }\n",
        "\n",
        "    raise ValueError(f\"Cannot parse condition part: '{cond_str}'\")\n",
        "\n",
        "\n",
        "def parse_condition(condition_str: str) -> list[dict]:\n",
        "    \"\"\"\n",
        "    Split condition on AND, parse each part.\n",
        "    Returns a list of condition dicts \u2014 ALL must be True for the rule to match.\n",
        "    \"\"\"\n",
        "    parts = [p.strip() for p in re.split(r\"\\bAND\\b\", condition_str, flags=re.IGNORECASE)]\n",
        "    return [parse_single_condition(p) for p in parts]\n",
        "\n",
        "\n",
        "def load_rules_from_df(rules_df: pd.DataFrame) -> list[dict]:\n",
        "    \"\"\"\n",
        "    Convert each DataFrame row into a rule dict.\n",
        "    Row order is preserved; priority is applied later in select_rule().\n",
        "\n",
        "    Required columns: section, rule_description, condition, decision, risk_level\n",
        "    \"\"\"\n",
        "    rules = []\n",
        "    for idx, row in rules_df.iterrows():\n",
        "        rules.append({\n",
        "            \"id\":            idx,\n",
        "            \"section\":       row[\"section\"],\n",
        "            \"label\":         row[\"rule_description\"],\n",
        "            \"condition_str\": row[\"condition\"],\n",
        "            \"conditions\":    parse_condition(row[\"condition\"]),\n",
        "            \"decision\":      row[\"decision\"],\n",
        "            \"risk_level\":    row[\"risk_level\"],\n",
        "        })\n",
        "    return rules\n"
      ],
      "metadata": {
        "id": "0DnPgS5Geowp"
      },
      "execution_count": 108,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\n",
        "# STEP 2: EXTRACT MULTIPLE VARIABLES\n",
        "# \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\n",
        "def extract_variables(user_input: str) -> dict:\n",
        "    \"\"\"\n",
        "    Extract amount and credit_score from free-text input.\n",
        "\n",
        "    Strategy:\n",
        "      - Scan all numbers and classify by surrounding keyword context (40 chars before)\n",
        "      - \"credit / score / fico\" before number \u2192 credit_score\n",
        "      - \"loan / borrow / need / want / $\"  before number \u2192 amount\n",
        "      - Fallback by value range: 300\u2013850 \u2192 credit_score, otherwise \u2192 amount\n",
        "    \"\"\"\n",
        "    cleaned   = user_input.replace(\",\", \"\")\n",
        "    variables = {}\n",
        "\n",
        "    num_pattern    = re.compile(r\"\\$?(\\d+(?:\\.\\d+)?)\\s*(k?)\\b\")\n",
        "    credit_keywords = re.compile(r\"credit|score|fico\", re.IGNORECASE)\n",
        "    loan_keywords   = re.compile(r\"loan|borrow|need|want|get|apply|request|\\$\", re.IGNORECASE)\n",
        "\n",
        "    for m in num_pattern.finditer(cleaned):\n",
        "        pos = m.start()\n",
        "        val = float(m.group(1)) * (1000 if m.group(2).lower() == \"k\" else 1)\n",
        "        context_before = cleaned[max(0, pos - 40): pos]\n",
        "\n",
        "        if credit_keywords.search(context_before):\n",
        "            variables[\"credit_score\"] = val\n",
        "        elif loan_keywords.search(context_before):\n",
        "            if \"amount\" not in variables:\n",
        "                variables[\"amount\"] = val\n",
        "        elif 300 <= val <= 850:\n",
        "            if \"credit_score\" not in variables:\n",
        "                variables[\"credit_score\"] = val\n",
        "        else:\n",
        "            if \"amount\" not in variables:\n",
        "                variables[\"amount\"] = val\n",
        "\n",
        "    return variables\n",
        "\n"
      ],
      "metadata": {
        "id": "PpiDj0CWeo7S"
      },
      "execution_count": 109,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\n",
        "# STEP 3: SAFE CONDITION EVALUATOR (no eval())\n",
        "# \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\n",
        "def _apply_op(left: float, op: str, right: float) -> bool:\n",
        "    \"\"\"Apply a single comparison operator. No eval().\"\"\"\n",
        "    ops = {\n",
        "        \"<=\": left <= right,\n",
        "        \"<\":  left <  right,\n",
        "        \">=\": left >= right,\n",
        "        \">\":  left >  right,\n",
        "        \"=\":  left == right,\n",
        "        \"!=\": left != right,\n",
        "    }\n",
        "    if op not in ops:\n",
        "        raise ValueError(f\"Unsupported operator: {op}\")\n",
        "    return ops[op]\n",
        "\n",
        "\n",
        "def evaluate_single_condition(cond: dict, variables: dict) -> bool | None:\n",
        "    \"\"\"\n",
        "    Evaluate one parsed condition dict against extracted variables.\n",
        "    Returns:\n",
        "      True / False \u2192 evaluated successfully\n",
        "      None         \u2192 required variable is missing (triggers fallback)\n",
        "    \"\"\"\n",
        "    field = cond[\"field\"]\n",
        "    if field not in variables:\n",
        "        return None  # missing variable \u2192 can't evaluate\n",
        "\n",
        "    value = variables[field]\n",
        "\n",
        "    if cond[\"type\"] == \"simple\":\n",
        "        return _apply_op(value, cond[\"op\"], cond[\"threshold\"])\n",
        "\n",
        "    if cond[\"type\"] == \"chained\":\n",
        "        # e.g. 5000 < amount <= 20000\n",
        "        left_ok  = _apply_op(cond[\"low\"],  cond[\"low_op\"],  value)\n",
        "        right_ok = _apply_op(value, cond[\"high_op\"], cond[\"high\"])\n",
        "        return left_ok and right_ok\n",
        "\n",
        "    raise ValueError(f\"Unknown condition type: {cond['type']}\")\n",
        "\n",
        "\n",
        "def evaluate_rule(rule: dict, variables: dict) -> bool | None:\n",
        "    \"\"\"\n",
        "    Evaluate ALL conditions for a rule (AND logic).\n",
        "    Returns:\n",
        "      True  \u2192 all conditions pass\n",
        "      False \u2192 at least one condition fails\n",
        "      None  \u2192 a required variable is missing\n",
        "    \"\"\"\n",
        "    for cond in rule[\"conditions\"]:\n",
        "        result = evaluate_single_condition(cond, variables)\n",
        "        if result is None:\n",
        "            return None   # missing variable\n",
        "        if not result:\n",
        "            return False  # short-circuit AND\n",
        "    return True\n",
        "\n"
      ],
      "metadata": {
        "id": "oTWQPw7LepDz"
      },
      "execution_count": 110,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\n",
        "# STEP 4: PRIORITY STRATEGY\n",
        "# \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\n",
        "# Strategy:\n",
        "#   1. Collect ALL matching rules\n",
        "#   2. Pick the rule with the HIGHEST risk level (High > Medium > Low)\n",
        "#   3. Tie-break: first matching rule in DataFrame order wins\n",
        "\n",
        "RISK_PRIORITY = {\"High\": 3, \"Medium\": 2, \"Low\": 1}\n",
        "\n",
        "\n",
        "def select_rule(variables: dict, rules: list[dict]) -> tuple[dict | None, bool]:\n",
        "    \"\"\"\n",
        "    Returns (best_matching_rule, needs_more_info).\n",
        "    needs_more_info=True means at least one rule was skipped due to a missing variable.\n",
        "    \"\"\"\n",
        "    matched    = []\n",
        "    needs_info = False\n",
        "\n",
        "    for rule in rules:\n",
        "        result = evaluate_rule(rule, variables)\n",
        "        if result is True:\n",
        "            matched.append(rule)\n",
        "        elif result is None:\n",
        "            needs_info = True\n",
        "\n",
        "    if not matched:\n",
        "        return None, needs_info\n",
        "\n",
        "    # Stable sort: highest risk first; ties keep original DataFrame order\n",
        "    matched.sort(key=lambda r: RISK_PRIORITY.get(r[\"risk_level\"], 0), reverse=True)\n",
        "    return matched[0], False\n",
        "\n"
      ],
      "metadata": {
        "id": "Y33VDOHPepNx"
      },
      "execution_count": 111,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\n",
        "# STEP 5: FALLBACK HANDLING\n",
        "# \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\n",
        "FALLBACK_REASONING = (\n",
        "    \"We were unable to reach a decision because required information is missing or unclear. \"\n",
        "    \"Please provide both your requested loan amount and your credit score.\"\n",
        ")\n",
        "\n",
        "\n",
        "def build_fallback(user_input: str, variables: dict) -> dict:\n",
        "    return {\n",
        "        \"user_input\":    user_input,\n",
        "        \"amount\":        variables.get(\"amount\"),\n",
        "        \"credit_score\":  variables.get(\"credit_score\"),\n",
        "        \"section\":       \"N/A\",\n",
        "        \"matched_rule\":  \"N/A\",\n",
        "        \"condition_met\": \"N/A\",\n",
        "        \"decision\":      \"NEED_MORE_INFORMATION\",\n",
        "        \"risk_level\":    \"Unknown\",\n",
        "        \"reasoning\":     FALLBACK_REASONING,\n",
        "    }\n",
        "\n"
      ],
      "metadata": {
        "id": "uom46TDRgZS0"
      },
      "execution_count": 112,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\n",
        "# STEP 6: LLM EXPLANATION LAYER\n",
        "# \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\n",
        "def build_prompt(user_input: str, variables: dict, rule: dict) -> str:\n",
        "    amt    = f\"${variables['amount']:,.0f}\" if \"amount\"       in variables else \"N/A\"\n",
        "    credit = int(variables[\"credit_score\"]) if \"credit_score\" in variables else \"N/A\"\n",
        "    return (\n",
        "        \"You are a professional loan officer assistant. \"\n",
        "        \"A loan decision has already been made by our rule engine. \"\n",
        "        \"Your ONLY job is to write a clear, professional one sentence explanation \"\n",
        "        \"for the applicant. Do NOT change, question, or override the decision.\\n\\n\"\n",
        "        f\"Applicant Request : \\\"{user_input}\\\"\\n\"\n",
        "        f\"Loan Amount       : {amt}\\n\"\n",
        "        f\"Credit Score      : {credit}\\n\"\n",
        "        f\"Loan Category     : {rule['section']}\\n\"\n",
        "        f\"Applied Rule      : {rule['label']}\\n\"\n",
        "        f\"Condition Met     : {rule['condition_str']}\\n\"\n",
        "        f\"Decision          : {rule['decision']}\\n\"\n",
        "        f\"Risk Level        : {rule['risk_level']}\\n\\n\"\n",
        "        \"Explanation:\"\n",
        "    )\n",
        "\n",
        "\n",
        "def get_llm_explanation(pipe, user_input: str, variables: dict, rule: dict) -> str:\n",
        "    \"\"\"Call Phi-3.5-mini-instruct for explanation only \u2014 never the decision.\"\"\"\n",
        "    messages = [{\"role\": \"user\", \"content\": build_prompt(user_input, variables, rule)}]\n",
        "    output   = pipe(messages, max_new_tokens=150, do_sample=False)\n",
        "\n",
        "    response = output[0][\"generated_text\"]\n",
        "    if isinstance(response, list):\n",
        "        for msg in reversed(response):\n",
        "            if isinstance(msg, dict) and msg.get(\"role\") == \"assistant\":\n",
        "                return msg[\"content\"].strip()\n",
        "    return str(response).strip()\n",
        "\n"
      ],
      "metadata": {
        "id": "CIOacQw7gZaI"
      },
      "execution_count": 113,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\n",
        "# STEP 7: MAIN DECISION PIPELINE\n",
        "# \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\n",
        "def process_loan_application(pipe, user_input: str, rules: list[dict]) -> dict:\n",
        "    \"\"\"\n",
        "    Full Level-2 pipeline:\n",
        "      Extract variables \u2192 Evaluate all rules \u2192 Apply priority \u2192\n",
        "      Fallback if needed \u2192 LLM explains \u2192 Structured output\n",
        "    \"\"\"\n",
        "    # 1. Extract variables from free text\n",
        "    variables = extract_variables(user_input)\n",
        "\n",
        "    # 2. Fallback: nothing could be extracted\n",
        "    if not variables:\n",
        "        return build_fallback(user_input, variables)\n",
        "\n",
        "    # 3. Select best matching rule with priority strategy\n",
        "    rule, needs_info = select_rule(variables, rules)\n",
        "\n",
        "    # 4. Fallback: no rule matched or a required variable was missing\n",
        "    if rule is None:\n",
        "        return build_fallback(user_input, variables)\n",
        "\n",
        "    # 5. LLM writes the explanation (never changes the decision)\n",
        "    reasoning = get_llm_explanation(pipe, user_input, variables, rule)\n",
        "\n",
        "    return {\n",
        "        \"user_input\":    user_input,\n",
        "        \"amount\":        variables.get(\"amount\"),\n",
        "        \"credit_score\":  variables.get(\"credit_score\"),\n",
        "        \"section\":       rule[\"section\"],\n",
        "        \"matched_rule\":  rule[\"label\"],\n",
        "        \"condition_met\": rule[\"condition_str\"],\n",
        "        \"decision\":      rule[\"decision\"],      # \u2190 Set by Python rule engine\n",
        "        \"risk_level\":    rule[\"risk_level\"],    # \u2190 Set by Python rule engine\n",
        "        \"reasoning\":     reasoning,             # \u2190 Generated by LLM\n",
        "    }\n",
        "\n",
        "\n",
        "def print_result(result: dict):\n",
        "    icons = {\n",
        "        \"APPROVED\":              \"\u2705\",\n",
        "        \"MANUAL_REVIEW\":         \"\ud83d\udd0d\",\n",
        "        \"REJECTED\":              \"\u274c\",\n",
        "        \"NEED_MORE_INFORMATION\": \"\u2753\",\n",
        "    }\n",
        "    icon  = icons.get(result[\"decision\"], \"\")\n",
        "    amt   = f\"${result['amount']:,.0f}\"      if result.get(\"amount\")        else \"N/A\"\n",
        "    score = str(int(result[\"credit_score\"])) if result.get(\"credit_score\")  else \"N/A\"\n",
        "\n",
        "    print(\"=\" * 65)\n",
        "    print(f\"  Input        : {result['user_input']}\")\n",
        "    print(f\"  Amount       : {amt}\")\n",
        "    print(f\"  Credit Score : {score}\")\n",
        "    print(f\"  Section      : {result['section']}\")\n",
        "    print(f\"  Rule         : {result['matched_rule']}\")\n",
        "    print(f\"  Condition    : {result['condition_met']}\")\n",
        "    print(f\"  Decision     : {icon} {result['decision']}\")\n",
        "    print(f\"  Risk Level   : {result['risk_level']}\")\n",
        "    print(f\"  Reasoning    :\")\n",
        "    print(f\"    {result['reasoning']}\")\n",
        "    print(\"=\" * 35 + \"\\n\")\n",
        "\n"
      ],
      "metadata": {
        "id": "OjvJ_qTmgZfu"
      },
      "execution_count": 114,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\n",
        "# STEP 8: USER QUERY FUNCTION\n",
        "# \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\n",
        "\n",
        "# Load rules from DataFrame\n",
        "_rules = load_rules_from_df(df)\n",
        "\n",
        "# Build pipeline from your already-loaded model and tokenizer\n",
        "_pipe = pipeline(\n",
        "    \"text-generation\",\n",
        "    model=model,\n",
        "    tokenizer=tokenizer,\n",
        "    device_map=\"auto\",\n",
        "    max_new_tokens=150,\n",
        "    do_sample=False,\n",
        ")\n",
        "\n",
        "\n",
        "def user_query(query: str):\n",
        "    \"\"\"\n",
        "    Process a single loan request query end-to-end.\n",
        "\n",
        "    Args:\n",
        "        query: Natural language loan request including amount and optionally credit score.\n",
        "               e.g. \"I need a loan of 25000. My credit score is 680.\"\n",
        "\n",
        "    Usage:\n",
        "        user_query(\"I need a loan of 3000.\")\n",
        "        user_query(\"I want 25000 loan, my credit score is 720.\")\n",
        "        user_query(\"Apply for 50000, score is 580.\")\n",
        "    \"\"\"\n",
        "    result = process_loan_application(_pipe, query, _rules)\n",
        "    print_result(result)\n",
        "\n"
      ],
      "metadata": {
        "id": "kjKqnQDFgt9i"
      },
      "execution_count": 117,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\n",
        "# TEST CASES \u2014 run each line individually\n",
        "# \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\n",
        "\n",
        "# \u2705 APPROVED (3 cases)\n",
        "# user_query(\"I need a loan of 3000 for furniture.\")\n",
        "# user_query(\"Can I borrow $1500? My credit score is 750.\")\n",
        "# user_query(\"I want a loan of 15000 and my credit score is 720.\")\n",
        "\n",
        "# \ud83d\udd0d MANUAL_REVIEW (3 cases)\n",
        "# user_query(\"I need 10000 for medical bills. My score is 650.\")\n",
        "# user_query(\"Requesting a loan of 25000, credit score is 710.\")\n",
        "# user_query(\"I want 18000 loan, score is 580.\")\n",
        "\n",
        "# \u274c REJECTED (3 cases)\n",
        "# user_query(\"I need 30000 but my credit score is 620.\")\n",
        "# user_query(\"Apply for 50000 loan. My credit score is 550.\")\n",
        "# user_query(\"I want 200000 for real estate.\")\n",
        "\n",
        "# \u2753 NEED_MORE_INFORMATION (fallback cases)\n",
        "# user_query(\"I need a loan please.\")\n",
        "# user_query(\"My credit score is 700.\")"
      ],
      "metadata": {
        "id": "bmbCtBN8guEl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "user_query(\"I need a loan of 3000 for furniture.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "89OwWsJfhF-f",
        "outputId": "f7854f71-965a-4817-b89d-dbd618bacc71"
      },
      "execution_count": 119,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Both `max_new_tokens` (=150) and `max_length`(=20) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "=================================================================\n",
            "  Input        : I need a loan of 3000 for furniture.\n",
            "  Amount       : $3,000\n",
            "  Credit Score : N/A\n",
            "  Section      : Loan\n",
            "  Rule         : Small loan auto approved\n",
            "  Condition    : amount <= 5000\n",
            "  Decision     : \u2705 APPROVED\n",
            "  Risk Level   : Low\n",
            "  Reasoning    :\n",
            "    Your application for a $3,000 loan for furniture has been approved based on our rule engine's criteria for small loans, with a low risk level and an approved status.\n",
            "===================================\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "user_query(\"Can I borrow $1500? My credit score is 750.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tzYDLtevhGHg",
        "outputId": "70f2ad99-e720-4919-b4e3-376369313800"
      },
      "execution_count": 120,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Both `max_new_tokens` (=150) and `max_length`(=20) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "=================================================================\n",
            "  Input        : Can I borrow $1500? My credit score is 750.\n",
            "  Amount       : $1,500\n",
            "  Credit Score : 750\n",
            "  Section      : Loan\n",
            "  Rule         : Small loan auto approved\n",
            "  Condition    : amount <= 5000\n",
            "  Decision     : \u2705 APPROVED\n",
            "  Risk Level   : Low\n",
            "  Reasoning    :\n",
            "    Your application for a $1,500 small loan has been approved based on your credit score of 750, aligning with our rule for small loans under $5,000, and is categorized as low risk.\n",
            "===================================\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "user_query(\"I need 30000 but my credit score is 620.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GsjQtSVQiWJd",
        "outputId": "1c067208-f75e-46f7-975c-263b93e90ffa"
      },
      "execution_count": 121,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Both `max_new_tokens` (=150) and `max_length`(=20) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "=================================================================\n",
            "  Input        : I need 30000 but my credit score is 620.\n",
            "  Amount       : $30,000\n",
            "  Credit Score : 620\n",
            "  Section      : Loan\n",
            "  Rule         : High loan with low credit rejected\n",
            "  Condition    : amount > 20000 AND credit_score < 700\n",
            "  Decision     : \u274c REJECTED\n",
            "  Risk Level   : High\n",
            "  Reasoning    :\n",
            "    The loan application for $30,000 was rejected due to a credit score below the threshold of 700, aligning with the rule for high loan amounts with low credit scores, indicating a high risk level.\n",
            "===================================\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "user_query(\"Apply for 50000 loan. My credit score is 550.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m-C5-n9Mibw2",
        "outputId": "29dce8c4-1e48-4ea1-84c4-05e23b8c4910"
      },
      "execution_count": 122,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Both `max_new_tokens` (=150) and `max_length`(=20) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "=================================================================\n",
            "  Input        : Apply for 50000 loan. My credit score is 550.\n",
            "  Amount       : $50,000\n",
            "  Credit Score : 550\n",
            "  Section      : Loan\n",
            "  Rule         : High loan with low credit rejected\n",
            "  Condition    : amount > 20000 AND credit_score < 700\n",
            "  Decision     : \u274c REJECTED\n",
            "  Risk Level   : High\n",
            "  Reasoning    :\n",
            "    The loan application for $50,000 was rejected due to a high risk level, as the applicant's credit score of 550 did not meet the criteria of being above 700 for such a substantial loan amount.\n",
            "===================================\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "user_query(\"I want 200000 for real estate.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nhmVajMDijbN",
        "outputId": "8b1b8a31-dfe4-4e38-c5aa-2f4ea47942a6"
      },
      "execution_count": 123,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Both `max_new_tokens` (=150) and `max_length`(=20) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "=================================================================\n",
            "  Input        : I want 200000 for real estate.\n",
            "  Amount       : $200,000\n",
            "  Credit Score : N/A\n",
            "  Section      : Loan\n",
            "  Rule         : Very large loan rejection\n",
            "  Condition    : amount > 100000\n",
            "  Decision     : \u274c REJECTED\n",
            "  Risk Level   : High\n",
            "  Reasoning    :\n",
            "    The loan application for $200,000 in real estate has been rejected due to the high risk level associated with the very large loan amount, as per the rule engine's assessment.\n",
            "===================================\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "user_query(\"I need a loan please.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RiL2zpHZip-x",
        "outputId": "53a634fc-ebe6-4847-de24-456f667a6596"
      },
      "execution_count": 124,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "=================================================================\n",
            "  Input        : I need a loan please.\n",
            "  Amount       : N/A\n",
            "  Credit Score : N/A\n",
            "  Section      : N/A\n",
            "  Rule         : N/A\n",
            "  Condition    : N/A\n",
            "  Decision     : \u2753 NEED_MORE_INFORMATION\n",
            "  Risk Level   : Unknown\n",
            "  Reasoning    :\n",
            "    We were unable to reach a decision because required information is missing or unclear. Please provide both your requested loan amount and your credit score.\n",
            "===================================\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "user_query(\"My credit score is 700.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M9VzF7I7i08N",
        "outputId": "89048630-3ea4-4d50-bc20-9952a796529e"
      },
      "execution_count": 125,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "=================================================================\n",
            "  Input        : My credit score is 700.\n",
            "  Amount       : N/A\n",
            "  Credit Score : 700\n",
            "  Section      : N/A\n",
            "  Rule         : N/A\n",
            "  Condition    : N/A\n",
            "  Decision     : \u2753 NEED_MORE_INFORMATION\n",
            "  Risk Level   : Unknown\n",
            "  Reasoning    :\n",
            "    We were unable to reach a decision because required information is missing or unclear. Please provide both your requested loan amount and your credit score.\n",
            "===================================\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "user_query(\"I want to buy new car and its price is $16500 and my score is 921\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yV87ahi8i48t",
        "outputId": "13a9635d-878a-4b1e-ef9b-7b186c0101ab"
      },
      "execution_count": 126,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Both `max_new_tokens` (=150) and `max_length`(=20) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "=================================================================\n",
            "  Input        : I want to buy new car and its price is $16500 and my score is 921\n",
            "  Amount       : $16,500\n",
            "  Credit Score : 921\n",
            "  Section      : Loan\n",
            "  Rule         : Medium loan review\n",
            "  Condition    : 5000 < amount <= 20000\n",
            "  Decision     : \ud83d\udd0d MANUAL_REVIEW\n",
            "  Risk Level   : Medium\n",
            "  Reasoning    :\n",
            "    Your application for a $16,500 car loan with a credit score of 921 has been flagged for a manual review due to the loan amount falling within the medium risk category as per our rule engine's assessment.\n",
            "===================================\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "user_query(\"I need a big loan but my credit is bad.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1AN-mUyMjU6e",
        "outputId": "3e25203b-a405-4a7d-a7b1-d5a11324dcdd"
      },
      "execution_count": 127,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "=================================================================\n",
            "  Input        : I need a big loan but my credit is bad.\n",
            "  Amount       : N/A\n",
            "  Credit Score : N/A\n",
            "  Section      : N/A\n",
            "  Rule         : N/A\n",
            "  Condition    : N/A\n",
            "  Decision     : \u2753 NEED_MORE_INFORMATION\n",
            "  Risk Level   : Unknown\n",
            "  Reasoning    :\n",
            "    We were unable to reach a decision because required information is missing or unclear. Please provide both your requested loan amount and your credit score.\n",
            "===================================\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "vW7wY992jjze"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### AND Logic\n",
        "Conditions are split on the AND keyword, parsed into individual fragments, and evaluated one by one. All fragments must return True for a rule to match. If any fragment fails, the rule is immediately dismissed. No eval() is used at any point.\n",
        "### Rule Priority Strategy\n",
        "All rules are evaluated and every match is collected. The highest risk-level match wins \u2014 High beats Medium, Medium beats Low. Ties are broken by row order in the DataFrame. This ensures the most conservative decision always prevails.\n",
        "### Fallback Behavior\n",
        "NEED_MORE_INFORMATION is returned when the input contains no extractable variables, or when no rule produces a definitive match. The LLM is skipped entirely in this case and the applicant is prompted to resubmit with complete details.\n",
        "### System Limitations\n",
        "Variable extraction depends on keyword proximity and can misclassify ambiguous phrasing. OR conditions and nested logic are not supported. The priority strategy always escalates to the strictest outcome, which may be overly conservative for some use cases. LLM explanations are non-deterministic in wording, which may be a concern in regulated environments."
      ],
      "metadata": {
        "id": "oLXFdoOLkNj8"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "fdApKzkGkVgO"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}